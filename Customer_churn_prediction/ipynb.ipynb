{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba0543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb98add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths - adjust if your file name/location differs\n",
    "RAW_CSV = '../data/raw/WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
    "PROCESSED_CSV = '../data/processed/churn_processed.csv'\n",
    "MODEL_PATH = '../models/churn_model.pkl'\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(os.path.dirname(PROCESSED_CSV), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
    "\n",
    "# Load raw data\n",
    "df = pd.read_csv(r\"C:\\FSDS_GENAI2\\Customer_Churn_Prediction_Project\\WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c4375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info and missing values\n",
    "df.info()\n",
    "print('\\nMissing values per column:')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb598b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TotalCharges to numeric  and inspect\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "print('TotalCharges nulls:', df['TotalCharges'].isnull().sum())\n",
    "\n",
    "# Fill missing TotalCharges with median\n",
    "df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee80fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# EDA - distribution of target and key features\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Churn', data=df)\n",
    "plt.title('Churn distribution')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(df['tenure'], kde=False, bins=30)\n",
    "plt.title('Tenure distribution')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(x='Churn', y='MonthlyCharges', data=df)\n",
    "plt.title('MonthlyCharges by Churn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1ece30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing & feature engineering\n",
    "df_proc = df.copy()\n",
    "\n",
    "# Drop customerID if exists\n",
    "if 'customerID' in df_proc.columns:\n",
    "    df_proc = df_proc.drop(columns=['customerID'])\n",
    "\n",
    "# Binary mapping for common Yes/No columns\n",
    "binary_map = {'Yes':1, 'No':0}\n",
    "for c in ['Partner','Dependents','PhoneService','PaperlessBilling','Churn']:\n",
    "    if c in df_proc.columns:\n",
    "        df_proc[c] = df_proc[c].map(binary_map)\n",
    "\n",
    "# Map gender\n",
    "if 'gender' in df_proc.columns:\n",
    "    df_proc['gender'] = df_proc['gender'].map({'Male':1, 'Female':0})\n",
    "\n",
    "# One-hot encode multi-categorical cols\n",
    "to_dummify = ['MultipleLines','InternetService','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies','Contract','PaymentMethod']\n",
    "existing = [c for c in to_dummify if c in df_proc.columns]\n",
    "df_proc = pd.get_dummies(df_proc, columns=existing, drop_first=True)\n",
    "\n",
    "print('Processed shape:', df_proc.shape)\n",
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50383fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed dataset for reproducibility\n",
    "df_proc.to_csv(PROCESSED_CSV, index=False)\n",
    "print('Saved processed CSV to', PROCESSED_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ba99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df_proc.drop(columns=['Churn'])\n",
    "y = df_proc['Churn']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d3c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models and compare\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, n_estimators=200)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    proba = model.predict_proba(X_test)[:,1]\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    auc = roc_auc_score(y_test, proba)\n",
    "    results.append((name, acc, f1, auc))\n",
    "    print(f\"{name}: Acc={acc:.4f}, F1={f1:.4f}, AUC={auc:.4f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['model','accuracy','f1','auc']).sort_values('accuracy', ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee778d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best model (by accuracy) and save\n",
    "best_name = results_df.iloc[0]['model']\n",
    "best_model = models[best_name]\n",
    "print('Best model:', best_name)\n",
    "\n",
    "# Save model with joblib/pickle\n",
    "joblib.dump(best_model, MODEL_PATH)\n",
    "print('Saved model to', MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290517b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed evaluation of best model\n",
    "best = joblib.load(MODEL_PATH)\n",
    "preds = best.predict(X_test)\n",
    "proba = best.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(classification_report(y_test, preds))\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.3f}')\n",
    "plt.plot([0,1],[0,1],'--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc022431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP explainability (optional - can be slow)\n",
    "try:\n",
    "    import shap\n",
    "    explainer = shap.Explainer(best)\n",
    "    shap_values = explainer(X_test)\n",
    "    shap.summary_plot(shap_values, X_test)\n",
    "except Exception as e:\n",
    "    print('SHAP failed or is slow in this environment:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d154787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save X_test and y_test for reproducible evaluation by app or tests\n",
    "X_test.to_csv('../data/processed/X_test.csv', index=False)\n",
    "y_test.to_csv('../data/processed/y_test.csv', index=False)\n",
    "print('Saved X_test and y_test to data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a66ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8bc1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e53389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce44896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae3c60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3241093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f7a02c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
